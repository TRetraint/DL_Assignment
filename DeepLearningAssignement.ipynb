{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningAssignement.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV9xXJDhY-b9"
      },
      "source": [
        "# Deep Learning Assignement Notebook\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEWFF_s2X64e"
      },
      "source": [
        "from keras.datasets import mnist\r\n",
        "\r\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\r\n",
        "print(len(Y_train),len(X_train),len(X_test),len(Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyM0tNi8c2_7"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "import seaborn as sns\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "np.random.seed(100)\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import itertools\r\n",
        "\r\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\r\n",
        "from keras.optimizers import RMSprop\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.callbacks import ReduceLROnPlateau, Callback\r\n",
        "\r\n",
        "\r\n",
        "sns.set(style='white', context='notebook', palette='deep')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv7hfF48dPS0"
      },
      "source": [
        "g = sns.countplot(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiwle9D-es3s"
      },
      "source": [
        "img = np.squeeze(X_train[0])\r\n",
        "plt.imshow(img, cmap='gray')\r\n",
        "plt.show()\r\n",
        "print(Y_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHlm7Y74jBeB"
      },
      "source": [
        "# Data Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXjgeYbQgp7q"
      },
      "source": [
        "# Normalize the data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF1sdjk3jOLH"
      },
      "source": [
        "X_train = X_train.reshape(-1,28,28,1)\r\n",
        "X_test = X_test.reshape(-1,28,28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD_l_mTFj0OT"
      },
      "source": [
        "Y_train = to_categorical(Y_train, num_classes = 10)\r\n",
        "Y_test = to_categorical(Y_test, num_classes = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SVAyJgQj37-"
      },
      "source": [
        "random_seed = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3t_iq3Tj7Lz"
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zocYsw9EkHCN"
      },
      "source": [
        "from keras.models import  Sequential\r\n",
        "from keras.layers.core import  Lambda , Dense, Flatten, Dropout\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Conv2D(32,(3,3), activation='relu'))\r\n",
        "model.add(BatchNormalization(axis=1))\r\n",
        "model.add(MaxPool2D())\r\n",
        "model.add(Dropout(0.3))\r\n",
        "model.add(BatchNormalization(axis=1))\r\n",
        "model.add(Convolution2D(64,(3,3), activation='relu'))\r\n",
        "model.add(BatchNormalization(axis=1))\r\n",
        "model.add(Convolution2D(64,(3,3), activation='relu'))\r\n",
        "model.add(MaxPooling2D())\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dropout(0.3))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dense(512, activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dense(10, activation = \"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3uowL9DkKRG"
      },
      "source": [
        "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FgiPGU3kMms"
      },
      "source": [
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR40kv28kPPf"
      },
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', \r\n",
        "                                            patience=3, \r\n",
        "                                            verbose=1, \r\n",
        "                                            factor=0.5, \r\n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkug8WHJkRJC"
      },
      "source": [
        "epochs = 30\r\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0qhYIYfkbAD"
      },
      "source": [
        "datagen = ImageDataGenerator(\r\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\r\n",
        "        samplewise_center=False,  # set each sample mean to 0\r\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\r\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\r\n",
        "        zca_whitening=False,  # apply ZCA whitening\r\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\r\n",
        "        zoom_range = 0.1, # Randomly zoom image \r\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\r\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\r\n",
        "        horizontal_flip=False,  # randomly flip images\r\n",
        "        vertical_flip=False)  # randomly flip images\r\n",
        "\r\n",
        "\r\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFWGvsX2rbWg"
      },
      "source": [
        "ACCURACY_THRESHOLD = 0.99\r\n",
        "LOSS_THRESHOLD = 0.01\r\n",
        "class myCallback(Callback): \r\n",
        "    def on_epoch_end(self, epoch, logs={}): \r\n",
        "        if(logs.get('accuracy') > ACCURACY_THRESHOLD) or (logs.get('loss') < LOSS_THRESHOLD):   \r\n",
        "          print(\"\\nWe have reached %2.2f%% accuracy or %2.2f%% loss, so we will stopping training.\" %(ACCURACY_THRESHOLD*100, LOSS_THRESHOLD*100) )   \r\n",
        "          self.model.stop_training = True\r\n",
        "\r\n",
        "callback = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcAsOtxqke7F"
      },
      "source": [
        "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\r\n",
        "                              epochs = epochs, validation_data = (X_val,Y_val),\r\n",
        "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\r\n",
        "                              , callbacks=[callback,learning_rate_reduction])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKrRjYcQzcCr"
      },
      "source": [
        "fig, ax = plt.subplots(2,1)\r\n",
        "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\r\n",
        "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\r\n",
        "legend = ax[0].legend(loc='best', shadow=True)\r\n",
        "\r\n",
        "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\r\n",
        "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\r\n",
        "legend = ax[1].legend(loc='best', shadow=True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNIZ6TLLSKTM"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\r\n",
        "                          normalize=False,\r\n",
        "                          title='Confusion matrix',\r\n",
        "                          cmap=plt.cm.Blues):\r\n",
        "    \"\"\"\r\n",
        "    This function prints and plots the confusion matrix.\r\n",
        "    Normalization can be applied by setting `normalize=True`.\r\n",
        "    \"\"\"\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "    plt.title(title)\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(classes))\r\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\r\n",
        "    plt.yticks(tick_marks, classes)\r\n",
        "\r\n",
        "    if normalize:\r\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
        "\r\n",
        "    thresh = cm.max() / 2.\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        plt.text(j, i, cm[i, j],\r\n",
        "                 horizontalalignment=\"center\",\r\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('True label')\r\n",
        "    plt.xlabel('Predicted label')\r\n",
        "\r\n",
        "# Predict the values from the validation dataset\r\n",
        "Y_pred = model.predict(X_val)\r\n",
        "# Convert predictions classes to one hot vectors \r\n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \r\n",
        "# Convert validation observations to one hot vectors\r\n",
        "Y_true = np.argmax(Y_val,axis = 1) \r\n",
        "# compute the confusion matrix\r\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \r\n",
        "# plot the confusion matrix\r\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ny9MetvKL-C"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Activation\r\n",
        "\r\n",
        "model0 = Sequential()\r\n",
        "model0.add(Flatten())\r\n",
        "model0.add(Dense(units=256, input_shape=(784,)))\r\n",
        "model0.add(Activation('relu'))\r\n",
        "model0.add(Dense(units=100))\r\n",
        "model0.add(Activation('relu'))\r\n",
        "model0.add(Dense(units=10))\r\n",
        "model0.add(Activation('softmax'))\r\n",
        "\r\n",
        "model0.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTA3nqTJR0QI"
      },
      "source": [
        "ACCURACY_THRESHOLD = 0.95\r\n",
        "LOSS_THRESHOLD = 0.05\r\n",
        "history = model0.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\r\n",
        "                              epochs = epochs, validation_data = (X_val,Y_val),\r\n",
        "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\r\n",
        "                              , callbacks=[callback,learning_rate_reduction])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Y1x4XeSuhK"
      },
      "source": [
        "model0.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iTcBe_WTCPk"
      },
      "source": [
        "fig, ax = plt.subplots(2,1)\r\n",
        "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\r\n",
        "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\r\n",
        "legend = ax[0].legend(loc='best', shadow=True)\r\n",
        "\r\n",
        "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\r\n",
        "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\r\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq_f3CLYGVjs"
      },
      "source": [
        "# Predict the values from the validation dataset\r\n",
        "Y_pred = model0.predict(X_val)\r\n",
        "# Convert predictions classes to one hot vectors \r\n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \r\n",
        "# Convert validation observations to one hot vectors\r\n",
        "Y_true = np.argmax(Y_val,axis = 1) \r\n",
        "# compute the confusion matrix\r\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \r\n",
        "# plot the confusion matrix\r\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}